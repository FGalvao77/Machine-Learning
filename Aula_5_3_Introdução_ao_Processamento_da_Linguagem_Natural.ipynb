{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aula 5.3 - Introdução ao Processamento da Linguagem Natural.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNTuDDRPzHHBtErFZAvAnD2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FGalvao77/Machine-Learning/blob/main/Aula_5_3_Introdu%C3%A7%C3%A3o_ao_Processamento_da_Linguagem_Natural.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjDlva3qYbSX"
      },
      "source": [
        "# **Introdução ao Processamento da Linguagem Natural**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h0oF4iFqL-I"
      },
      "source": [
        "A capacidade de comunicar-se é uma das principais características que nos permitem viver em sociedade. E a tecnologia é um aspecto que vem gradativamente evoluindo e facilitando a forma com que nos comunicamos.\n",
        "\n",
        "Nesse sentindo, está cada vez mais fácil usar aplicativos para troca de mensagens e já existem, inclusive, sistemas que usam `machine learning` para simular uma conversa como se fossem uma pessoa respondendo. Quanta inovação, não é mesmo?!\n",
        "\n",
        "Esses sistemas são chamados de chatbots. Eles já estão presentes em diversos sites de comércio eletrônico e em serviços de atendimento de várias empresas. Neles o usuário geralmente é apresentado a um chat com algumas opções de serviço e o assistente virtual vai direcionando o utilizador para determinado setor de atendimento da empresa, com base em suas respostas em mensagens de texto.\n",
        "\n",
        "E como esses sistemas fazem isso? Como eles conseguem entender as mensagens do\n",
        "usuário?\n",
        "\n",
        "Bem, por trás dessa tecnologia existe uma área da computação que é chamada de\n",
        "`Processamento da Linguagem Natural`, tem o objetivo de fazer com que um sistema consiga entender a linguagem dos humanos, ou seja, entender o que nós escrevemos ou falamos.\n",
        "\n",
        "**O Processamento da Linguagem Natural, também representado pela sigla PLN, ou NLP do inglês Natural Language Processing, utiliza conceitos baseados em linguística e regras gramaticais para a construção de algoritmos, que possam extrair alguma informação ou entendimento**.\n",
        "\n",
        "_Dentre as aplicações do PNL pode-se destacar a sumarização ou resumo de textos, que permite, por exemplo, captar apenas as ideias principais que contém o sentido de um texto ou de um livro. Outra aplicação são os aplicativos de tradução que utilizam o reconhecimento de voz do usuário para traduzir uma frase. O PNL pode ser aplicado ainda em recuperação de informação, chatbots, entre outras utilidades._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFl9aljaqyzf"
      },
      "source": [
        "Caro, cursista, agora você será apresentado, de fato, a alguns conceitos importantes no aprendizado de PLN. São eles: `Corpus, Tokenização, e Stop words`.\n",
        "\n",
        "O **Corpus** é representado por um conjunto de textos escritos em um determinado idioma, que foram manualmente anotados e servirá de validação para as análises que serão realizadas.\n",
        "\n",
        "Já a **Tokenização**, refere-se a divisão de um texto em partes menores que representam as palavras, ou também chamadas de tokens, e podem ser separadas por espaços, vírgulas ou pontuações.\n",
        "\n",
        "Por último, mas não menos importante, os **Stop words**. Eles são palavras que geralmente são removidas no início do processamento dos textos para acelerar esse processo, porém a retirada dessas palavras não afeta a compreensão do mesmo.\n",
        "\n",
        "Após a definição destes conceitos, para que você os entenda melhor e consiga utilizá-los em seu cotidiano de programador é importante acompanhar a aplicação do que foi estudado. Nesse caso, será usando uma biblioteca do python chamada de NLTK que significa Natural Language Toolkit. Então, com o ambiente do jupyter aberto, faça inicialmente o download da biblioteca com o comando “`!pip install nltk`”."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9G_oGCbdqwG",
        "outputId": "6ad9128e-aa36-4a9b-a860-101209c04bde"
      },
      "source": [
        "# instalando a biblioteca\n",
        "!pip install nltk"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zRTFq20YVEu"
      },
      "source": [
        "# importando a biblioteca\n",
        "import nltk"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shSJDFZGYePd",
        "outputId": "61b458cd-cd7a-411c-a9c2-1ed93dc0ecfc"
      },
      "source": [
        "# baixando as stop words\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVMU2f5nYeM0",
        "outputId": "6922e965-2d5d-4a28-8a2a-d9c48eca212f"
      },
      "source": [
        "# stop words em português\n",
        "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "\n",
        "# imprimindo as stop words do português\n",
        "print(stopwords)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['de', 'a', 'o', 'que', 'e', 'é', 'do', 'da', 'em', 'um', 'para', 'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'ao', 'ele', 'das', 'à', 'seu', 'sua', 'ou', 'quando', 'muito', 'nos', 'já', 'eu', 'também', 'só', 'pelo', 'pela', 'até', 'isso', 'ela', 'entre', 'depois', 'sem', 'mesmo', 'aos', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'você', 'essa', 'num', 'nem', 'suas', 'meu', 'às', 'minha', 'numa', 'pelos', 'elas', 'qual', 'nós', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'dele', 'tu', 'te', 'vocês', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'está', 'estamos', 'estão', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'estávamos', 'estavam', 'estivera', 'estivéramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estivéssemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'há', 'havemos', 'hão', 'houve', 'houvemos', 'houveram', 'houvera', 'houvéramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houvéssemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houverá', 'houveremos', 'houverão', 'houveria', 'houveríamos', 'houveriam', 'sou', 'somos', 'são', 'era', 'éramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'fôramos', 'seja', 'sejamos', 'sejam', 'fosse', 'fôssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'será', 'seremos', 'serão', 'seria', 'seríamos', 'seriam', 'tenho', 'tem', 'temos', 'tém', 'tinha', 'tínhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tivéramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tivéssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'terá', 'teremos', 'terão', 'teria', 'teríamos', 'teriam']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tvHPVqKYeKQ",
        "outputId": "350147b3-17ea-4367-82f9-f07d5ae8bf02"
      },
      "source": [
        "# importando a biblioteca de tokenização\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# recursos necessários para realizar a tokenização\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCuhPj-TYeH8"
      },
      "source": [
        "# instanciando uma frase para aplicação dos nossos testes\n",
        "frase = 'Eu dirigo devagar porque nós queremos ver os animais!'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAyaxVrWYeFu",
        "outputId": "96f0e233-7c70-437c-88dd-d3763b5de464"
      },
      "source": [
        "# aplicando a tokenização na frase instanciada\n",
        "tokens = word_tokenize(frase)\n",
        "\n",
        "# visualizando o resultado\n",
        "print(tokens)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Eu', 'dirigo', 'devagar', 'porque', 'nós', 'queremos', 'ver', 'os', 'animais', '!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3Rr1HdOYeDt",
        "outputId": "93e5d4a7-b334-4060-a79c-6227c8418fee"
      },
      "source": [
        "# realizando um \"for\" para excluir os stop words\n",
        "for t in tokens:\n",
        "  if t not in stopwords:\n",
        "    print(t)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Eu\n",
            "dirigo\n",
            "devagar\n",
            "porque\n",
            "queremos\n",
            "ver\n",
            "animais\n",
            "!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvpwzdbRlCSc"
      },
      "source": [
        "Outra técnica muito importante na análise de textos, é a identificação da frequência e importância que uma palavra pode ter em um texto.\n",
        "\n",
        "Existe um cálculo estatístico chamado de `TF-IDF`, essa sigla vem do inglês **Term Frequency – Inverse Document Frequency**, e quer dizer: _Frequência do termo - Frequência Inversa do Documento_. Este cálculo identifica a importância que um termo tem em um texto, ou seja, ele permite que você descubra quais termos são mais relevantes em um dado texto ou documento.\n",
        "\n",
        "Em linhas gerais o `TF-IDF busca atribuir um valor que representa um peso para definir a importância do termo em um documento, com base na frequência em que ele ocorre (TF), compensando, porém, esse peso, caso a ocorrência desse termo seja muito grande (IDF)`.\n",
        "\n",
        "Em resumo, se um termo aparece algumas vezes no texto, o valor do TF-IDF aumenta, significando que aquela palavra é importante, porém se esse termo se repete bastante, esse valor é compensado, e a importância dele é diminuída.\n",
        "\n",
        "Deu pra entender o TF-IDF? Agora acompanhe um exemplo prático, para melhorar\n",
        "sua compreensão sobre esse assunto, utilizando o módulo “TfidfVectorizer” da biblioteca sklearn para calcular os valores de TF-IDF de um texto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsahPOWoYeBk"
      },
      "source": [
        "# importando as bibliotecas\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer # para calcular os valores de TF-IDF\n",
        "import pandas as pd"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgRmfL2YkAjw"
      },
      "source": [
        "# instanciando uma frase\n",
        "texto1 = 'A matemática é muito importante para compreendermos como a natureza funciona.'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfF_35-eYd_P"
      },
      "source": [
        "# instanciando o módulo\n",
        "tf_idf = TfidfVectorizer()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyXA5GPGYd80",
        "outputId": "caf72d5c-72f5-4cca-da5a-124b0124ac15"
      },
      "source": [
        "# utilizando o fit transform para termos uma matriz\n",
        "vetor = tf_idf.fit_transform([texto1])\n",
        "\n",
        "# imprimindo o vetor\n",
        "print(vetor)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 2)\t0.35355339059327373\n",
            "  (0, 6)\t0.35355339059327373\n",
            "  (0, 0)\t0.35355339059327373\n",
            "  (0, 1)\t0.35355339059327373\n",
            "  (0, 7)\t0.35355339059327373\n",
            "  (0, 3)\t0.35355339059327373\n",
            "  (0, 5)\t0.35355339059327373\n",
            "  (0, 4)\t0.35355339059327373\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77a3zj4fYd6a",
        "outputId": "6e36404c-cda4-49c5-b336-926321132754"
      },
      "source": [
        "# transformando a matriz em um array\n",
        "vetor = vetor.todense()\n",
        "print(vetor)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.35355339 0.35355339 0.35355339 0.35355339 0.35355339 0.35355339\n",
            "  0.35355339 0.35355339]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd1CM9O5muCN",
        "outputId": "96e978c0-95bc-455c-abc6-3989362b3a10"
      },
      "source": [
        "# utilizando a função \".get_feature_names()\"\n",
        "# para mapear as palavras\n",
        "nomes = tf_idf.get_feature_names()\n",
        "\n",
        "print(nomes)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['como', 'compreendermos', 'funciona', 'importante', 'matemática', 'muito', 'natureza', 'para']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7bg_0Mpmt_V",
        "outputId": "af77949f-126a-42bc-9639-f50efd9235da"
      },
      "source": [
        "# transformando o resultado em dataframe\n",
        "df = pd.DataFrame(vetor, columns=nomes)\n",
        "\n",
        "# visualizando o dataframe criado\n",
        "print(df)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       como  compreendermos  funciona  ...     muito  natureza      para\n",
            "0  0.353553        0.353553  0.353553  ...  0.353553  0.353553  0.353553\n",
            "\n",
            "[1 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HlPvNEno0oN"
      },
      "source": [
        "**Usando um novo texto**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwodxcIBmt86"
      },
      "source": [
        "# instanciando uma nova frase\n",
        "texto2 = 'A matemática é incrível, quanto mais estudo matemática, mais eu consigo aprender matemática!'"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c1pb0Smmt5G"
      },
      "source": [
        "# instanciando o módulo\n",
        "tf_idf = TfidfVectorizer()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luCcY1momt3q",
        "outputId": "7bf7d3e3-972d-43d5-cebf-4cbf0b1fcfe1"
      },
      "source": [
        "# utilizando o fit transform para termos uma matriz\n",
        "vetor = tf_idf.fit_transform([texto2])\n",
        "\n",
        "# imprimindo o vetor\n",
        "print(vetor)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 0)\t0.22941573387056174\n",
            "  (0, 1)\t0.22941573387056174\n",
            "  (0, 3)\t0.22941573387056174\n",
            "  (0, 2)\t0.22941573387056174\n",
            "  (0, 5)\t0.4588314677411235\n",
            "  (0, 7)\t0.22941573387056174\n",
            "  (0, 4)\t0.22941573387056174\n",
            "  (0, 6)\t0.6882472016116852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2CmeNTlmt0U",
        "outputId": "722eb059-c5a9-46c3-ab08-68135d2a6f83"
      },
      "source": [
        "# transformando a matriz em um array\n",
        "vetor = vetor.todense()\n",
        "print(vetor)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.22941573 0.22941573 0.22941573 0.22941573 0.22941573 0.45883147\n",
            "  0.6882472  0.22941573]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VDLmIusmtyB",
        "outputId": "54f19d7c-fd5b-4ed6-f072-a1541dc2f9fc"
      },
      "source": [
        "# utilizando a função \".get_feature_names()\"\n",
        "# para mapear as palavras\n",
        "nomes = tf_idf.get_feature_names()\n",
        "\n",
        "print(nomes)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['aprender', 'consigo', 'estudo', 'eu', 'incrível', 'mais', 'matemática', 'quanto']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "of5TAKPFmtwJ",
        "outputId": "de0658c7-7ce4-4b87-dcd8-532bda1a504d"
      },
      "source": [
        "# transformando o resultado em dataframe\n",
        "df = pd.DataFrame(vetor, columns=nomes)\n",
        "\n",
        "# visualizando o dataframe criado\n",
        "print(df)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   aprender   consigo    estudo  ...      mais  matemática    quanto\n",
            "0  0.229416  0.229416  0.229416  ...  0.458831    0.688247  0.229416\n",
            "\n",
            "[1 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x13GptU5qCsO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfwwleOHqCpi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}